{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcbd6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Outlier detection\n",
    "from scipy.stats import zscore\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='white', context='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4a6aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp-pc\\appdata\\roaming\\python\\python311\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp-pc\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4189d198",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data_Train.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mData_Train.xlsx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# assuming it's in the same directory\u001b[39;00m\n\u001b[32m      4\u001b[39m data.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[39m, in \u001b[36mread_excel\u001b[39m\u001b[34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[32m    494\u001b[39m     should_close = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     io = \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine != io.engine:\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    503\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine should not be specified when passing \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    505\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[39m, in \u001b[36mExcelFile.__init__\u001b[39m\u001b[34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[39m\n\u001b[32m   1548\u001b[39m     ext = \u001b[33m\"\u001b[39m\u001b[33mxls\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1549\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1550\u001b[39m     ext = \u001b[43minspect_excel_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m   1552\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1555\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mExcel file format cannot be determined, you must specify \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1556\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33man engine manually.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1557\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[39m, in \u001b[36minspect_excel_format\u001b[39m\u001b[34m(content_or_path, storage_options)\u001b[39m\n\u001b[32m   1399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m   1400\u001b[39m     content_or_path = BytesIO(content_or_path)\n\u001b[32m-> \u001b[39m\u001b[32m1402\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m   1404\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[32m   1405\u001b[39m     stream = handle.handle\n\u001b[32m   1406\u001b[39m     stream.seek(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'Data_Train.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel(\"Data_Train.xlsx\")  # assuming it's in the same directory\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf6c1299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10683 entries, 0 to 10682\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Airline          10683 non-null  object\n",
      " 1   Date_of_Journey  10683 non-null  object\n",
      " 2   Source           10683 non-null  object\n",
      " 3   Destination      10683 non-null  object\n",
      " 4   Route            10682 non-null  object\n",
      " 5   Dep_Time         10683 non-null  object\n",
      " 6   Arrival_Time     10683 non-null  object\n",
      " 7   Duration         10683 non-null  object\n",
      " 8   Total_Stops      10682 non-null  object\n",
      " 9   Additional_Info  10683 non-null  object\n",
      " 10  Price            10683 non-null  int64 \n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 918.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c1322ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Duration\n",
       "2h 50m     550\n",
       "1h 30m     386\n",
       "2h 45m     337\n",
       "2h 55m     337\n",
       "2h 35m     329\n",
       "          ... \n",
       "31h 30m      1\n",
       "30h 25m      1\n",
       "42h 5m       1\n",
       "4h 10m       1\n",
       "47h 40m      1\n",
       "Name: count, Length: 368, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Duration\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4c1205e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>10683.0</td>\n",
       "      <td>9087.064121</td>\n",
       "      <td>4611.359167</td>\n",
       "      <td>1759.0</td>\n",
       "      <td>5277.0</td>\n",
       "      <td>8372.0</td>\n",
       "      <td>12373.0</td>\n",
       "      <td>79512.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count         mean          std     min     25%     50%      75%  \\\n",
       "Price  10683.0  9087.064121  4611.359167  1759.0  5277.0  8372.0  12373.0   \n",
       "\n",
       "           max  \n",
       "Price  79512.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc6d82b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10683, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6fb6c",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43de7d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline            0\n",
       "Date_of_Journey    0\n",
       "Source             0\n",
       "Destination        0\n",
       "Route              1\n",
       "Dep_Time           0\n",
       "Arrival_Time       0\n",
       "Duration           0\n",
       "Total_Stops        1\n",
       "Additional_Info    0\n",
       "Price              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42d0df7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Route'] = data['Route'].ffill(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee9241ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Route'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9795b70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Total_Stops'] = data['Total_Stops'].ffill(axis=0)\n",
    "data['Total_Stops'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9924002e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Airline            0\n",
       "Date_of_Journey    0\n",
       "Source             0\n",
       "Destination        0\n",
       "Route              0\n",
       "Dep_Time           0\n",
       "Arrival_Time       0\n",
       "Duration           0\n",
       "Total_Stops        0\n",
       "Additional_Info    0\n",
       "Price              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f530c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Journey_day\"] = pd.to_datetime(data[\"Date_of_Journey\"],format=\"%d/%m/%Y\").dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5210a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Journey_month\"] = pd.to_datetime(data[\"Date_of_Journey\"],format=\"%d/%m/%Y\").dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d3c13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Airline</th>\n",
       "      <th>Date_of_Journey</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Route</th>\n",
       "      <th>Dep_Time</th>\n",
       "      <th>Arrival_Time</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Total_Stops</th>\n",
       "      <th>Additional_Info</th>\n",
       "      <th>Price</th>\n",
       "      <th>Journey_day</th>\n",
       "      <th>Journey_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>24/03/2019</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR √¢‚Ä†‚Äô DEL</td>\n",
       "      <td>22:20:00</td>\n",
       "      <td>2025-03-22 01:10:00</td>\n",
       "      <td>2h 50m</td>\n",
       "      <td>non-stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>3897</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Air India</td>\n",
       "      <td>2019-01-05 00:00:00</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU √¢‚Ä†‚Äô IXR √¢‚Ä†‚Äô BBI √¢‚Ä†‚Äô BLR</td>\n",
       "      <td>05:50:00</td>\n",
       "      <td>13:15:00</td>\n",
       "      <td>7h 25m</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>7662</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jet Airways</td>\n",
       "      <td>2019-09-06 00:00:00</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Cochin</td>\n",
       "      <td>DEL √¢‚Ä†‚Äô LKO √¢‚Ä†‚Äô BOM √¢‚Ä†‚Äô COK</td>\n",
       "      <td>09:25:00</td>\n",
       "      <td>2025-06-10 04:25:00</td>\n",
       "      <td>19h</td>\n",
       "      <td>2 stops</td>\n",
       "      <td>No info</td>\n",
       "      <td>13882</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>2019-12-05 00:00:00</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>CCU √¢‚Ä†‚Äô NAG √¢‚Ä†‚Äô BLR</td>\n",
       "      <td>18:05:00</td>\n",
       "      <td>23:30:00</td>\n",
       "      <td>5h 25m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>6218</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IndiGo</td>\n",
       "      <td>2019-01-03 00:00:00</td>\n",
       "      <td>Banglore</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>BLR √¢‚Ä†‚Äô NAG √¢‚Ä†‚Äô DEL</td>\n",
       "      <td>16:50:00</td>\n",
       "      <td>21:35:00</td>\n",
       "      <td>4h 45m</td>\n",
       "      <td>1 stop</td>\n",
       "      <td>No info</td>\n",
       "      <td>13302</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Airline      Date_of_Journey    Source Destination  \\\n",
       "0       IndiGo           24/03/2019  Banglore   New Delhi   \n",
       "1    Air India  2019-01-05 00:00:00   Kolkata    Banglore   \n",
       "2  Jet Airways  2019-09-06 00:00:00     Delhi      Cochin   \n",
       "3       IndiGo  2019-12-05 00:00:00   Kolkata    Banglore   \n",
       "4       IndiGo  2019-01-03 00:00:00  Banglore   New Delhi   \n",
       "\n",
       "                         Route  Dep_Time         Arrival_Time Duration  \\\n",
       "0                  BLR √¢‚Ä†‚Äô DEL  22:20:00  2025-03-22 01:10:00   2h 50m   \n",
       "1  CCU √¢‚Ä†‚Äô IXR √¢‚Ä†‚Äô BBI √¢‚Ä†‚Äô BLR  05:50:00             13:15:00   7h 25m   \n",
       "2  DEL √¢‚Ä†‚Äô LKO √¢‚Ä†‚Äô BOM √¢‚Ä†‚Äô COK  09:25:00  2025-06-10 04:25:00      19h   \n",
       "3          CCU √¢‚Ä†‚Äô NAG √¢‚Ä†‚Äô BLR  18:05:00             23:30:00   5h 25m   \n",
       "4          BLR √¢‚Ä†‚Äô NAG √¢‚Ä†‚Äô DEL  16:50:00             21:35:00   4h 45m   \n",
       "\n",
       "  Total_Stops Additional_Info  Price  Journey_day  Journey_month  \n",
       "0    non-stop         No info   3897           24              3  \n",
       "1     2 stops         No info   7662            5              1  \n",
       "2     2 stops         No info  13882            6              9  \n",
       "3      1 stop         No info   6218            5             12  \n",
       "4      1 stop         No info  13302            3              1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bd0d115",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class 'datetime.time'> is not convertible to datetime, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m data[\u001b[33m\"\u001b[39m\u001b[33mDep_hour\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDep_Time\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.dt.hour\n\u001b[32m      2\u001b[39m data[\u001b[33m'\u001b[39m\u001b[33mDep_min\u001b[39m\u001b[33m'\u001b[39m] = pd.to_datetime(data[\u001b[33m\"\u001b[39m\u001b[33mDep_Time\u001b[39m\u001b[33m\"\u001b[39m]).dt.minute\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1046\u001b[39m, in \u001b[36mto_datetime\u001b[39m\u001b[34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[39m\n\u001b[32m   1044\u001b[39m             result = arg.tz_localize(\u001b[33m\"\u001b[39m\u001b[33mutc\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1045\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[32m-> \u001b[39m\u001b[32m1046\u001b[39m     cache_array = \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1047\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array.empty:\n\u001b[32m   1048\u001b[39m         result = arg.map(cache_array)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:250\u001b[39m, in \u001b[36m_maybe_cache\u001b[39m\u001b[34m(arg, format, cache, convert_listlike)\u001b[39m\n\u001b[32m    248\u001b[39m unique_dates = unique(arg)\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) < \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     cache_dates = \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:455\u001b[39m, in \u001b[36m_convert_listlike_datetimes\u001b[39m\u001b[34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[39m\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33mmixed\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    453\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m result, tz_parsed = \u001b[43mobjects_to_datetime64ns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[43m=\u001b[49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[32m    467\u001b[39m     dta = DatetimeArray(result, dtype=tz_to_dtype(tz_parsed))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2177\u001b[39m, in \u001b[36mobjects_to_datetime64ns\u001b[39m\u001b[34m(data, dayfirst, yearfirst, utc, errors, allow_object)\u001b[39m\n\u001b[32m   2174\u001b[39m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[32m   2175\u001b[39m data = np.array(data, copy=\u001b[38;5;28;01mFalse\u001b[39;00m, dtype=np.object_)\n\u001b[32m-> \u001b[39m\u001b[32m2177\u001b[39m result, tz_parsed = \u001b[43mtslib\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2179\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2182\u001b[39m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[43m=\u001b[49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2183\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2186\u001b[39m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[32m   2187\u001b[39m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[32m   2188\u001b[39m     \u001b[38;5;66;03m# Return i8 values to denote unix timestamps\u001b[39;00m\n\u001b[32m   2189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result.view(\u001b[33m\"\u001b[39m\u001b[33mi8\u001b[39m\u001b[33m\"\u001b[39m), tz_parsed\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\tslib.pyx:402\u001b[39m, in \u001b[36mpandas._libs.tslib.array_to_datetime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\tslib.pyx:551\u001b[39m, in \u001b[36mpandas._libs.tslib.array_to_datetime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\tslib.pyx:540\u001b[39m, in \u001b[36mpandas._libs.tslib.array_to_datetime\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: <class 'datetime.time'> is not convertible to datetime, at position 0"
     ]
    }
   ],
   "source": [
    "data[\"Dep_hour\"] = pd.to_datetime(data[\"Dep_Time\"]).dt.hour\n",
    "data['Dep_min'] = pd.to_datetime(data[\"Dep_Time\"]).dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d89055",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e50db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your DataFrame is named df\n",
    "data['Date_of_Journey'] = pd.to_datetime(data['Date_of_Journey'],format = \"%d/%m/%Y\")\n",
    "data['Day_of_Week'] = data['Date_of_Journey'].dt.day_name()\n",
    "data.head()\n",
    "# Observation: The Date_of_Journey column has been converted to extract the corresponding day of the week.\n",
    "# This allows us to identify whether a journey occurred on a weekday or weekend,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33724cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Clean the column ‚Äî convert everything to string and strip whitespace\n",
    "data['Arrival_Time'] = data['Arrival_Time'].astype(str).str.strip()\n",
    "\n",
    "# Step 2: Handle entries missing seconds (e.g., \"13:15\" ‚Üí \"13:15:00\")\n",
    "def standardize_time_format(x):\n",
    "    if len(x.split()) == 2:  # Format: \"YYYY-MM-DD HH:MM:SS\"\n",
    "        return x\n",
    "    elif len(x.split(\":\")) == 2:  # Format: \"HH:MM\"\n",
    "        return \"1900-01-01 \" + x + \":00\"\n",
    "    elif len(x.split(\":\")) == 3:  # Format: \"HH:MM:SS\"\n",
    "        return \"1900-01-01 \" + x\n",
    "    else:\n",
    "        return pd.NA  # For truly invalid entries\n",
    "\n",
    "# Apply the formatting function\n",
    "data['Arrival_Time_clean'] = data['Arrival_Time'].apply(standardize_time_format)\n",
    "\n",
    "# Step 3: Parse the cleaned datetime\n",
    "arrival_datetime = pd.to_datetime(data['Arrival_Time_clean'], errors='coerce')\n",
    "\n",
    "# Step 4: Extract hour and minute\n",
    "data['Arrival_hour'] = arrival_datetime.dt.hour\n",
    "data['Arrival_min'] = arrival_datetime.dt.minute\n",
    "\n",
    "# Optional: Drop the cleaned column if not needed\n",
    "# data.drop(columns=['Arrival_Time_clean'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4e402e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4709b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7af658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assigning and converting Duration column into list\n",
    "duration = list(data[\"Duration\"])\n",
    "\n",
    "for i in range(len(duration)):\n",
    "    if len(duration[i].split()) != 2:    # Check if duration contains only hour or mins\n",
    "        if \"h\" in duration[i]:\n",
    "            duration[i] = duration[i].strip() + \" 0m\"   # Adds 0 minute\n",
    "        else:\n",
    "            duration[i] = \"0h \" + duration[i]           # Adds 0 hour\n",
    "\n",
    "duration_hours = []\n",
    "duration_mins = []\n",
    "for i in range(len(duration)):\n",
    "    duration_hours.append(int(duration[i].split(sep = \"h\")[0]))    # Extract hours from duration\n",
    "    duration_mins.append(int(duration[i].split(sep = \"m\")[0].split()[-1]))   # Extracts only minutes from duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7831e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Duration_hours\"] = duration_hours\n",
    "data[\"Duration_mins\"] = duration_mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4389a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Airline\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d7445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(y = \"Price\", x = \"Airline\", data = data.sort_values(\"Price\", ascending = False), kind=\"boxen\", height = 6, aspect = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faac5041",
   "metadata": {},
   "outputs": [],
   "source": [
    "Airline = data[[\"Airline\"]]\n",
    "Airline = pd.get_dummies(Airline,drop_first = True).astype(int)\n",
    "Airline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f66a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Source\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d0afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.catplot(y = \"Price\", x = \"Source\", data = data.sort_values(\"Price\", ascending = False), kind=\"boxen\", height = 4, aspect = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412dde0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Source = data[[\"Source\"]]\n",
    "Source = pd.get_dummies(Source,drop_first = True).astype(int)\n",
    "Source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27799348",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Destination\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f998d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Destination = data[[\"Destination\"]]\n",
    "Destination = pd.get_dummies(Destination,drop_first = True).astype(int)\n",
    "Destination.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fc7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Route\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35acb800",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed158296",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([\"Route\", \"Additional_Info\"], axis = 1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data[\"Total_Stops\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b60f98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace({\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4273b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d3ce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([data,Airline,Source,Destination],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f8bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop([\"Dep_Time\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b092ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e32101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a2316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9521966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_excel(r\"Test_set.xlsx\")\n",
    "\n",
    "# Basic info\n",
    "print(\"Test data Info\")\n",
    "print(\"-\"*75)\n",
    "print(test_data.info())\n",
    "\n",
    "print(\"\\nNull values:\")\n",
    "print(\"-\"*75)\n",
    "test_data.dropna(inplace=True)\n",
    "print(test_data.isnull().sum())\n",
    "\n",
    "# --- üóìÔ∏è Feature Engineering: Dates ---\n",
    "test_data[\"Journey_Date\"] = pd.to_datetime(test_data[\"Date_of_Journey\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "test_data[\"Journey_day\"] = test_data[\"Journey_Date\"].dt.day\n",
    "test_data[\"Journey_month\"] = test_data[\"Journey_Date\"].dt.month\n",
    "test_data.drop([\"Date_of_Journey\", \"Journey_Date\"], axis=1, inplace=True)\n",
    "\n",
    "# --- ‚è∞ Departure & Arrival Time ---\n",
    "test_data[\"Dep_Time\"] = pd.to_datetime(test_data[\"Dep_Time\"], format=\"%H:%M\", errors=\"coerce\")\n",
    "test_data[\"Dep_hour\"] = test_data[\"Dep_Time\"].dt.hour\n",
    "test_data[\"Dep_min\"]  = test_data[\"Dep_Time\"].dt.minute\n",
    "test_data.drop(\"Dep_Time\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "test_data[\"Arrival_Time\"] = pd.to_datetime(test_data[\"Arrival_Time\"], errors=\"coerce\")\n",
    "test_data[\"Arrival_hour\"] = test_data[\"Arrival_Time\"].dt.hour\n",
    "test_data[\"Arrival_min\"] = test_data[\"Arrival_Time\"].dt.minute\n",
    "\n",
    "# --- ‚è±Ô∏è Duration Fix ---\n",
    "duration = test_data[\"Duration\"].tolist()\n",
    "fixed_duration = []\n",
    "\n",
    "for dur in duration:\n",
    "    parts = dur.split()\n",
    "    if len(parts) == 1:\n",
    "        dur = \"0h \" + dur if \"m\" in dur else dur + \" 0m\"\n",
    "    fixed_duration.append(dur)\n",
    "\n",
    "hours = [int(d.split(\"h\")[0]) for d in fixed_duration]\n",
    "mins = [int(d.split(\"m\")[0].split()[-1]) for d in fixed_duration]\n",
    "\n",
    "test_data[\"Duration_hours\"] = hours\n",
    "test_data[\"Duration_mins\"] = mins\n",
    "test_data.drop(\"Duration\", axis=1, inplace=True)\n",
    "\n",
    "# --- üéØ Categorical Encoding ---\n",
    "Airline      = pd.get_dummies(test_data[\"Airline\"], drop_first=True)\n",
    "Source       = pd.get_dummies(test_data[\"Source\"], drop_first=True)\n",
    "Destination  = pd.get_dummies(test_data[\"Destination\"], drop_first=True)\n",
    "\n",
    "# Drop less useful columns\n",
    "test_data.drop([\"Airline\", \"Source\", \"Destination\", \"Route\", \"Additional_Info\"], axis=1, inplace=True)\n",
    "\n",
    "# Replace Total_Stops text with numeric\n",
    "stop_map = {\"non-stop\": 0, \"1 stop\": 1, \"2 stops\": 2, \"3 stops\": 3, \"4 stops\": 4}\n",
    "test_data[\"Total_Stops\"] = test_data[\"Total_Stops\"].map(stop_map)\n",
    "\n",
    "# Final dataframe\n",
    "data_test = pd.concat([test_data, Airline, Source, Destination], axis=1)\n",
    "\n",
    "print(\"\\nFinal Shape of test data:\", data_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1966d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c4c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ed229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a2a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a79ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbbdbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a252012",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878029af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3705e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715d7d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f671dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b55fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drops = [\"Airline\",\"Date_of_Journey\",'Source', 'Destination', 'Dep_Time','Arrival_Time']\n",
    "\n",
    "train_data1.drop([\"Day_of_Week\",\"Duration\",\"Airline\",\"Date_of_Journey\",'Source', 'Destination', 'Dep_Time','Arrival_Time',],axis=1,inplace=True)\n",
    "train_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c1651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.drop('Airline_Trujet',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531f5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(\"Dep_Time\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b55299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed543a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f59f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b482c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.drop('Arrival_Time_clean',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e05679a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15d50d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.drop(['Dep_hour', 'Dep_min'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050567a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c215b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd43d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.rename(columns={\n",
    "    'Air India': 'Airline_Air India',\n",
    "    'GoAir': 'Airline_GoAir',\n",
    "    'IndiGo': 'Airline_IndiGo',\n",
    "    'Jet Airways': 'Airline_Jet Airways',\n",
    "    'Jet Airways Business': 'Airline_Jet Airways Business',\n",
    "    'Multiple carriers': 'Airline_Multiple carriers',\n",
    "    'Multiple carriers Premium economy': 'Airline_Multiple carriers Premium economy',\n",
    "    'SpiceJet': 'Airline_SpiceJet',\n",
    "    'Vistara': 'Airline_Vistara',\n",
    "    'Vistara Premium economy': 'Airline_Vistara Premium economy',\n",
    "    \n",
    "    'Chennai': 'Source_Chennai',\n",
    "    'Delhi': 'Source_Delhi',             # This refers to 'Source_Delhi'\n",
    "    'Kolkata': 'Source_Kolkata',\n",
    "    'Mumbai': 'Source_Mumbai',\n",
    "    \n",
    "    'Cochin': 'Destination_Cochin',\n",
    "    'Hyderabad': 'Destination_Hyderabad',\n",
    "    'New Delhi': 'Destination_New Delhi',\n",
    "},inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcfa7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cddfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'Price' from X since it's the target\n",
    "X_train = train_data1.drop('Price', axis=1)\n",
    "\n",
    "# Target variable\n",
    "y_train = train_data1['Price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5694883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure columns match ‚Äî fill missing columns in test data if needed\n",
    "for col in X_train.columns:\n",
    "    if col not in data_test.columns:\n",
    "        data_test[col] = 0  # Add missing columns with 0s (safe default)\n",
    "\n",
    "# Also remove extra columns in test set not in training set\n",
    "data_test = data_test[X_train.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d968ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Fit on training data\n",
    "lr_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd8ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ebe518",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78127b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f363729",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data1.drop(\"Price\",axis=1)\n",
    "Y = train_data1[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efff94d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0d6222",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493c068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b93646",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38687d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_lr_train = lr_model.predict(x_train)\n",
    "y_predict_lr_test = lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171427bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a49444",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = train_data1.dropna(subset=['Total_Stops'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb94e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db26a9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_lr_train = lr_model.predict(x_train)\n",
    "y_predict_lr_test = lr_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bd4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_train, y_predict_lr_train))\n",
    "print(\"\\n\")\n",
    "print(r2_score(y_test, y_predict_lr_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12835b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_model.fit(x_train, y_train)\n",
    "y_predict_rf_train = rf_model.predict(x_train)\n",
    "y_predict_rf_test = rf_model.predict(x_test)\n",
    "print(r2_score(y_train, y_predict_rf_train))\n",
    "print(\"\\n\")\n",
    "print(r2_score(y_test, y_predict_rf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf6aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target from training data\n",
    "X = train_data1.drop(['Price'], axis=1)\n",
    "y = train_data1['Price']\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dd4960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align column order\n",
    "train_data1.columns\n",
    "print(train_data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3ad20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa4fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bfef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32de8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.rename(columns={\n",
    "    # Airline columns\n",
    "    'Air India': 'Airline_Air India',\n",
    "    'GoAir': 'Airline_GoAir',\n",
    "    'IndiGo': 'Airline_IndiGo',\n",
    "    'Jet Airways': 'Airline_Jet Airways',\n",
    "    'Jet Airways Business': 'Airline_Jet Airways Business',\n",
    "    'Multiple carriers': 'Airline_Multiple carriers',\n",
    "    'Multiple carriers Premium economy': 'Airline_Multiple carriers Premium economy',\n",
    "    'SpiceJet': 'Airline_SpiceJet',\n",
    "    'Vistara': 'Airline_Vistara',\n",
    "    'Vistara Premium economy': 'Airline_Vistara Premium economy',\n",
    "\n",
    "    # Source columns\n",
    "    'Chennai': 'Source_Chennai',\n",
    "    'Delhi': 'Source_Delhi',\n",
    "    'Kolkata': 'Source_Kolkata',\n",
    "    'Mumbai': 'Source_Mumbai',\n",
    "\n",
    "    # Destination columns\n",
    "    'Cochin': 'Destination_Kolkata',\n",
    "    \n",
    "    'Hyderabad': 'Destination_Hyderabad',\n",
    "    'New Delhi': 'Destination_Delhi'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca14192",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10489358",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69ed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.rename(columns={\n",
    "    'Destination_New Delhi': 'Destination_Delhi',\n",
    "    'Destination_Cochin': 'Destination_Kolkata'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e9f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec10a7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35040704",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.rename(columns={\n",
    "    'Destination_New Delhi': 'Destination_Delhi',\n",
    "    'Destination_Cochin': 'Destination_Kolkata'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7940d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094d4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target from training data\n",
    "X = train_data1.drop(['Price'], axis=1)\n",
    "y = train_data1['Price']\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e87ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd44134",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4cf536",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e52c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01056ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a95e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40513f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eacce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_prices = model.predict(data_test)\n",
    "\n",
    "# Optional: convert to a dataframe for export or analysis\n",
    "import numpy as np\n",
    "results = pd.DataFrame({'Predicted_Price': np.round(predicted_prices, 2)})\n",
    "print(results.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3550a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184aadbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3cae88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e07d027",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3111ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Week'] = data['Day_of_Week'].isin(['Saturday', 'Sunday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "sns.countplot(data=data, x='Week', hue='Week')\n",
    "\n",
    "plt.title('weekend and weekday')\n",
    "plt.ylabel('Number of people travelled')\n",
    "plt.legend(title='Day Type', labels=['Weekday', 'Weekend'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Observation : The following bar graph shows that their are more people travel on \n",
    "                # weekday rather than weekend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e55d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['Week'])['Price'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee913fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.Figure(figsize=(2,2))\n",
    "sns.barplot(data=data, x='Week', y='Price', color='salmon', ci=None)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fae9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485639a4",
   "metadata": {},
   "source": [
    "# Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76be7170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot \n",
    "\n",
    "for column in data.columns :\n",
    "    plt.figure()\n",
    "    sns.scatterplot(data=data, x=column, y=data.index,hue=data.Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7114fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = data.select_dtypes(include=np.number).columns\n",
    "\n",
    "for column in res :\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.displot(data[column],color='darkorange',kind='kde')\n",
    "    # sns.displot(data[column],color='darkorange',kind='hist')\n",
    "\n",
    "# Observation : Here we can check the price and density of flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be245014",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in res :\n",
    "    plt.figure()\n",
    "    sns.boxplot(x = data[column], data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb150841",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95faffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew = data['Price'].skew()\n",
    "print(\"\\nSkew\\n\")\n",
    "print(skew)\n",
    "\n",
    "print(\"\\nKurt\\n\")\n",
    "kurt = data['Price'].kurt()\n",
    "print(kurt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3315681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    " \n",
    "z_scores = zscore(data['Price'])\n",
    "filtered_dataset = data[abs(z_scores) <= 3]\n",
    "filtered_dataset \n",
    "\n",
    "for column in res :\n",
    "    plt.figure()\n",
    "    sns.boxplot(x = data[column], data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate z-scores for the 'Starting_Salary' column\n",
    "print('Before outlier removal : ',data.shape)\n",
    "Pricing = zscore(data['Price'])\n",
    " \n",
    "# Define a threshold for identifying outliers\n",
    "threshold = 3\n",
    " \n",
    "# Find outliers only in the 'Starting_Salary' column\n",
    "outlier_Price = data[(np.abs(Pricing) > threshold)]\n",
    " \n",
    "print(f\"\\nNumber of outliers found in 'Price' using a threshold of {threshold}: {len(outlier_Price)}\")\n",
    "# print(\"\\n\",outliers_salary)\n",
    " \n",
    "# Remove outliers from the dataset\n",
    "dataset_cleaned = data[(np.abs(Pricing) <= threshold)]\n",
    "print('\\nAfter Z-Score approach (outliers in Price removed) : ',dataset_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff258120",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dataset_cleaned.select_dtypes(include=np.number).columns\n",
    "\n",
    "for column in res :\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.displot(dataset_cleaned[column],color='darkorange',kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00ece33",
   "metadata": {},
   "outputs": [],
   "source": [
    "skew = dataset_cleaned['Price'].skew()\n",
    "print(\"\\nSkew\\n\")\n",
    "print(skew)\n",
    "\n",
    "print(\"\\nKurt\\n\")\n",
    "kurt = dataset_cleaned['Price'].kurt()\n",
    "print(kurt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc0f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting box plot after outlier removal\n",
    "sns.boxplot(data=dataset_cleaned, x='Price')  # replace with your actual column\n",
    "plt.title('Box Plot after Removing Outliers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ebb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['Avg. Area Number of Bedrooms']\n",
    "Q1 = data['Price'].quantile(0.10)  # Q1\n",
    "Q3 = data['Price'].quantile(0.90)  # Q3\n",
    "IQR = Q3-Q1\n",
    "dataset = data[~((data['Price']<(Q1-1.5*IQR)) | (data['Price']>(Q3+1.5*IQR)))]\n",
    "print('After IQR approach : ',dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c2c257",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=dataset, x='Price')  # replace with your actual column\n",
    "plt.title('Box Plot after Removing Outliers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c7695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = data.select_dtypes(include=np.number).columns\n",
    "\n",
    "for column in res :\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.displot(data[column],color='darkorange',kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b140d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler , RobustScaler, StandardScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform(data[['Price']])\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=['Price'])\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694134aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=scaled_df, x='Price', kde=True)\n",
    " \n",
    "plt.title('Distribution of Scaled Original Price')\n",
    "plt.xlabel('Scaled Value (0-1)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2b8fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform(dataset[['Price']])\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=['Price'])\n",
    "scaled_df\n",
    "\n",
    "sns.displot(data=scaled_df, x='Price', kde=True)\n",
    " \n",
    "plt.title('Distribution of Scaled after removal of outlier in Price column')\n",
    "plt.xlabel('Scaled Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e3fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import RobustScaler\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Scale the 'Price' column using the outlier-free dataset\n",
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform(filtered_dataset[['Price']])\n",
    "\n",
    "# Step 2: Convert back to DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=['Price'])\n",
    "\n",
    "# Step 3: Plot the scaled distribution\n",
    "sns.displot(data=scaled_df, x='Price', kde=True, bins=30, aspect=1.5)\n",
    "\n",
    "# Step 4: Customize the plot\n",
    "plt.title('Distribution of Scaled Price After Outlier Removal')\n",
    "plt.xlabel('Scaled Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b97d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Scale the 'Price' column using the outlier-free dataset\n",
    "scaler = RobustScaler()\n",
    "scaled_data = scaler.fit_transform(dataset[['Price']])\n",
    "\n",
    "# Step 2: Convert back to DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=['Price'])\n",
    "\n",
    "# Step 3: Plot the scaled distribution\n",
    "sns.displot(data=scaled_df, x='Price', kde=True, bins=30, aspect=1.5)\n",
    "\n",
    "# Step 4: Customize the plot\n",
    "plt.title('Distribution of Scaled Price After Outlier Removal')\n",
    "plt.xlabel('Scaled Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a307867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1 already done: outlier removal using modified IQR\n",
    "# dataset is your outlier-free DataFrame\n",
    "\n",
    "# Step 2: Apply RobustScaler\n",
    "scaler = RobustScaler()\n",
    "scaled_price = scaler.fit_transform(dataset[['Price']])\n",
    "\n",
    "# Step 3: Create a scaled DataFrame for visualization or modeling\n",
    "scaled_df = pd.DataFrame(scaled_price, columns=['Price'])\n",
    "\n",
    "# Step 4: Plot the distribution\n",
    "sns.displot(data=scaled_df, x='Price', kde=True, bins=30, aspect=1.5)\n",
    "plt.title('Distribution of Scaled Price (After IQR Cleaning)')\n",
    "plt.xlabel('Scaled Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bdc1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875f8b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X_train = train_data.drop(['Price'], axis=1)\n",
    "y_train = train_data['Price']\n",
    "\n",
    "# test_data already aligned and cleaned in previous steps\n",
    "X_test = test_data  # this should already match X_train columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b756fe87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "# Fit on training data\n",
    "lr_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c22079",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0dab25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7058c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c50932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bffc3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ded23ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53e83d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7a4ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf84c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505abb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f2cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa2315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06efec11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6fd6b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ecea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db8c76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
